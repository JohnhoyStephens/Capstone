{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Notebook-Comprehensive Notebook detailing the process to the final model and project overview.\n",
    "\n",
    "# Overview of Project\n",
    " This project aims to utilize Illinois 2018 American Community Survey data to create an imcome predicitor to aid Illinois and governmental programs with their allocation of the programs. In particular programs such as SNAP and unemployment. This will allow for a faster application process due to better accuracy. This is very crucial in especially when looking at unemployment. This has been one of the most vital neccesities of this COVID-19 age due to the massive amount of layoff and furloughs done by organizations. In creating a better system to access these individuals and their income we can better deploy these services to the citizens that need them. More information on this topic can be found [here]\n",
    " \n",
    "# Data acquisition \n",
    " Prior to running any of the Jupyter Notbooks or data in this download the neccesary files andenvironments..\n",
    "\n",
    "Download [Andaconda](https://docs.anaconda.com/anaconda/install/) to be able to install the environment and use your preference of commandline options or Editor to view the data.\n",
    "Also go to this [Census Link](https://www2.census.gov/programs-surveys/acs/data/pums/2018/5-Year/) and down load the csv_hil.zip to acquires the data used in this project.\n",
    "\n",
    "### From the list options below choose the environments within this neccesary envrionment for your operating system.\n",
    "\n",
    "[`tens.yml`]\n",
    "\n",
    "To utilize Geopandas:\n",
    "\n",
    "[`Capstone.yml`]\n",
    "\n",
    "All files are located in the main directory and src folder.\n",
    "Run these two lines of code after the download to apply the kernals to your IDE.\n",
    "\n",
    "`python -m ipykernel install --user --name tens --display-name \"Python 3 (tens)\"` \n",
    "\n",
    "`python -m ipykernel install --user --name Capstone --display-name \"Python 3 (Capstone)\"`  \n",
    "\n",
    " \n",
    "# Goals:\n",
    "This project aims to:\n",
    "- Build a modle that predicts an individuals income based on multiple parameters such as property value, proterty taxes and number of people in a household."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# from src.js_functions import coeff_determination\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from src.js_functions import  process_data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../../Data/csv_hil/psam_h17.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The orginal dataframe will now processed via the process data function. For more about the cleaning and processing of the data [check out this notbook](../Explortatory/Data_cleaning_processing.ipynb) as well as [this py file](../../src/js_functions.py).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test=process_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at the first 5 rows of cleaned dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMOCP</th>\n",
       "      <th>NP</th>\n",
       "      <th>BDSP</th>\n",
       "      <th>INSP</th>\n",
       "      <th>RMSP</th>\n",
       "      <th>VALP</th>\n",
       "      <th>TAXAMT</th>\n",
       "      <th>ACR_&lt;1.0&gt;</th>\n",
       "      <th>ACR_&lt;2.0&gt;</th>\n",
       "      <th>ACR_&lt;3.0&gt;</th>\n",
       "      <th>...</th>\n",
       "      <th>YBL_&lt;13.0&gt;</th>\n",
       "      <th>YBL_&lt;14.0&gt;</th>\n",
       "      <th>YBL_&lt;15.0&gt;</th>\n",
       "      <th>YBL_&lt;16.0&gt;</th>\n",
       "      <th>YBL_&lt;17.0&gt;</th>\n",
       "      <th>YBL_&lt;18.0&gt;</th>\n",
       "      <th>YBL_&lt;19.0&gt;</th>\n",
       "      <th>YBL_&lt;20.0&gt;</th>\n",
       "      <th>YBL_&lt;21.0&gt;</th>\n",
       "      <th>YBL_&lt;22.0&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6894</th>\n",
       "      <td>652.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>3850.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>1206.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182231</th>\n",
       "      <td>1042.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>890.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80188</th>\n",
       "      <td>5217.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292305</th>\n",
       "      <td>2188.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SMOCP  NP  BDSP    INSP  RMSP      VALP   TAXAMT  ACR_<1.0>  \\\n",
       "6894     652.0   3   3.0   600.0   5.0  130000.0   3850.0        1.0   \n",
       "49998   1206.0   4   3.0   400.0   4.0  125000.0   3150.0        1.0   \n",
       "182231  1042.0   1   1.0   890.0   5.0  165000.0   3650.0        1.0   \n",
       "80188   5217.0   4   4.0  1200.0   7.0  650000.0  14000.0        1.0   \n",
       "292305  2188.0   2   3.0  2300.0   9.0  800000.0  14500.0        1.0   \n",
       "\n",
       "        ACR_<2.0>  ACR_<3.0>  ...  YBL_<13.0>  YBL_<14.0>  YBL_<15.0>  \\\n",
       "6894          0.0        0.0  ...         0.0         0.0         0.0   \n",
       "49998         0.0        0.0  ...         0.0         0.0         0.0   \n",
       "182231        0.0        0.0  ...         0.0         0.0         0.0   \n",
       "80188         0.0        0.0  ...         0.0         0.0         0.0   \n",
       "292305        0.0        0.0  ...         0.0         0.0         0.0   \n",
       "\n",
       "        YBL_<16.0>  YBL_<17.0>  YBL_<18.0>  YBL_<19.0>  YBL_<20.0>  \\\n",
       "6894           0.0         0.0         0.0         0.0         0.0   \n",
       "49998          0.0         0.0         0.0         0.0         0.0   \n",
       "182231         0.0         0.0         0.0         0.0         0.0   \n",
       "80188          0.0         0.0         0.0         0.0         0.0   \n",
       "292305         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "        YBL_<21.0>  YBL_<22.0>  \n",
       "6894           0.0         0.0  \n",
       "49998          0.0         0.0  \n",
       "182231         0.0         0.0  \n",
       "80188          0.0         0.0  \n",
       "292305         0.0         0.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "Each row represents a household.\n",
    "Below are the features for a given household.\n",
    "\n",
    "`y_train and y_test ` represent household income\n",
    "\n",
    "**SMOCP** -Selected monthly owner costs.\n",
    "\n",
    "**NP** -Number of persons associated with this housing record.\n",
    "\n",
    "**BDSP** -Number of bedrooms.\n",
    "\n",
    "**INSP** -5Fire/hazard/flood insurance yearly amount.\n",
    "\n",
    "**RMSP**-Number of rooms. \n",
    "\n",
    "**VALP** -Property value. \n",
    "\n",
    "**TAXAMT** -Property taxes. \n",
    "\n",
    "**ACR** -Lot size\n",
    "   - Each column for this feature represent differnt house lot sizes in a range\n",
    "\n",
    "**FS** -Yearly food stamp/Supplemental Nutrition Assistance Program (SNAP)\n",
    "recipiency\n",
    "\n",
    "   - Each column for this feature tell us where some one does or does not have SNAP\n",
    "\n",
    "**TOIL**-Flush toilet\n",
    "   - Each column for this feature has a toliet that flushes or not\n",
    "\n",
    "**VEH** -Number of vehicles\n",
    "   - Each column for this feature represents a differnt numbers of cars\n",
    "\n",
    "**YBL**-When structure first built\n",
    "   - Each column for this feature represent differnt house lot sizes in a range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is our baseline model.\n",
    "lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3847594087743529"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores= cross_val_score(lr,X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38422207389115826"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_rsqaured(lr,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basline model has a R-squared score of .38 so not to bad as basline model. Let's see if we can increase this value through a different algorithm. Overall, This initial model is telling us that 38% of the variance in the target column can be explained by the features we are using**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4883788705468357"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr=KNeighborsRegressor(n_neighbors=5)\n",
    "knr.fit(X_train,y_train)\n",
    "knr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1= cross_val_score(knr,X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25017895465649836"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_rsqaured(knr,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The with the KNN model the features account for 25% of the variance seen in the target column.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets run a Random forest regressor and see how this may preform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr=RandomForestRegressor(max_depth=10, min_samples_split= 4, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, min_samples_split=4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4711950787125593"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2= cross_val_score(rfr,X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40715365539405746"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_rsqaured(rfr,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The R-squared predictor\n",
    "from keras import backend as K\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    \"\"\"https://jmlb.github.io/ml/2017/03/20/CoeffDetermination_CustomMetric4Keras/\"\"\"\n",
    "\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-08, patience=0, verbose=1,\n",
    "                           mode='auto')\n",
    "callbacks_list = [early_stop]\n",
    "model=Sequential()\n",
    "model.add(Dense(50 ,activation=\"relu\",input_dim=47))\n",
    "model.add(Dense(25 ,activation=\"selu\"))\n",
    "model.add(Dense(1 ,activation='linear'))\n",
    "model.compile(loss=\"mse\",optimizer=\"adam\",metrics=[tf.keras.metrics.RootMeanSquaredError(),\"mae\",coeff_determination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 157760 samples, validate on 39441 samples\n",
      "Epoch 1/50\n",
      "157760/157760 [==============================] - 6s 38us/step - loss: 6525606460.7789 - root_mean_squared_error: 84935.6641 - mae: 49279.6484 - coeff_determination: 0.1464 - val_loss: 6560731825.3489 - val_root_mean_squared_error: 80860.3359 - val_mae: 47463.8516 - val_coeff_determination: 0.2373\n",
      "Epoch 2/50\n",
      "157760/157760 [==============================] - 6s 39us/step - loss: 6046045758.8763 - root_mean_squared_error: 80055.3594 - mae: 48082.0469 - coeff_determination: 0.2152 - val_loss: 6178551325.9871 - val_root_mean_squared_error: 79446.1875 - val_mae: 48200.5625 - val_coeff_determination: 0.2413\n",
      "Epoch 3/50\n",
      "157760/157760 [==============================] - 6s 37us/step - loss: 5989999164.2515 - root_mean_squared_error: 79081.4688 - mae: 47761.4453 - coeff_determination: 0.2244 - val_loss: 6348603322.9973 - val_root_mean_squared_error: 78870.1172 - val_mae: 46758.9570 - val_coeff_determination: 0.2585\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train,epochs=50,batch_size=50,validation_split=.2,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seeing as the Randrom forest Regressor performed the best let's test it on our test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41607874904279185"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_rsqaured(rfr,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **The model performs well on the test data where the level of vairance association is not to far off from the training data. With some more iteration we may be able to increase this value and create are more accurate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual=86708.29873633395, Predictied=86690.58098378546\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual=%s, Predictied=%s\" % (y_test.values.mean(),y_hat.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From this we can see that our actual value  and predicted value average do not differ to much which makes sense due to the model trying to acomodate all the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual=35000.0, Predictied=64016.95833267796\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual=%s, Predictied=%s\" % (y_test.values[0],y_hat[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, when we look at the individual values and their predicted income counterparts there is a large discrepancy in some case such as the first value of the test data being 35,000 and the predcited value being 64,000. This is something I expected due to combining all of the counties in one dataframe. This is due to the cost of living and overall socio-economic advantages or disadvantages of a county based on it geographical location**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End analysis conlusion:\n",
    "- The final model predicts about 40% of the vairiance seen within the data. \n",
    "- When you look at individual values there is about a 29,000 dollar differnce in those values.\n",
    "\n",
    "### Next steps:\n",
    "- I would like to continue to Iterate on the current model and reduce the amount of vairance seen between the actual and predicted values.\n",
    "- I would also like to subset the counties and see how that would affect the predicted values due to haveing more geographically related data.\n",
    "- Moreover, I would like to do some more feature enginerring to possiblty increase the R-Squared value.\n",
    "- Lastly, I would like to find more recent census data to have a better estimate to the current day household income."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tens)",
   "language": "python",
   "name": "tens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

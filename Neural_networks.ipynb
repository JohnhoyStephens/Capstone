{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,recall_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Imputed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HINCP_x</th>\n",
       "      <th>SMOCP</th>\n",
       "      <th>PUMA</th>\n",
       "      <th>NP</th>\n",
       "      <th>BDSP</th>\n",
       "      <th>INSP</th>\n",
       "      <th>RMSP</th>\n",
       "      <th>VALP</th>\n",
       "      <th>TAXAMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47900.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3108</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36100.0</td>\n",
       "      <td>691.0</td>\n",
       "      <td>2501</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3502</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3526</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88000.0</td>\n",
       "      <td>603.0</td>\n",
       "      <td>1204</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246497</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>1366.0</td>\n",
       "      <td>3208</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>6500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246498</th>\n",
       "      <td>150000.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>3208</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>10500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246499</th>\n",
       "      <td>85000.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>2601</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>5750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246500</th>\n",
       "      <td>117500.0</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>3407</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>11500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246501</th>\n",
       "      <td>89000.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3309</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246502 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HINCP_x   SMOCP  PUMA  NP  BDSP    INSP  RMSP      VALP   TAXAMT\n",
       "0        47900.0   260.0  3108   4   3.0   260.0   6.0     260.0    260.0\n",
       "1        36100.0   691.0  2501   2   3.0   600.0   6.0   35000.0    525.0\n",
       "2       100000.0   260.0  3502   1   0.0   260.0   1.0     260.0    260.0\n",
       "3        45000.0   260.0  3526   2   2.0   260.0   5.0     260.0    260.0\n",
       "4        88000.0   603.0  1204   3   2.0    20.0   4.0     140.0    525.0\n",
       "...          ...     ...   ...  ..   ...     ...   ...       ...      ...\n",
       "246497   30000.0  1366.0  3208   1   4.0     0.0  11.0  150000.0   6500.0\n",
       "246498  150000.0  2603.0  3208   4   4.0  1200.0   8.0  275000.0  10500.0\n",
       "246499   85000.0   751.0  2601   2   3.0   550.0   6.0  145000.0   5750.0\n",
       "246500  117500.0  1168.0  3407   2   4.0   990.0  10.0  500000.0  11500.0\n",
       "246501   89000.0   260.0  3309   4   2.0   260.0   4.0     260.0    260.0\n",
       "\n",
       "[246502 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"HINCP_x\",axis=1)\n",
    "y=df[\"HINCP_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss=ss.fit_transform(X_train)\n",
    "X_test_ss=ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8 ,activation=\"tanh\",input_shape=(8,)))\n",
    "model.add(Dense(4 ,activation=\"tanh\"))\n",
    "model.add(Dense(2 ,activation=\"relu\"))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse',optimizer=\"adam\",metrics=['mse','mae','accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 157760 samples, validate on 39441 samples\n",
      "Epoch 1/10\n",
      "157760/157760 [==============================] - 3s 19us/step - loss: 16271241571.2292 - mse: 16271211520.0000 - mae: 86744.8438 - accuracy: 0.0000e+00 - val_loss: 15988251157.8996 - val_mse: 15988250624.0000 - val_mae: 86507.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "157760/157760 [==============================] - 3s 20us/step - loss: 16269617206.7181 - mse: 16269637632.0000 - mae: 86735.6641 - accuracy: 1.2677e-05 - val_loss: 15986632039.2996 - val_mse: 15986634752.0000 - val_mae: 86498.4609 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "157760/157760 [==============================] - 3s 20us/step - loss: 16267992885.8742 - mse: 16268002304.0000 - mae: 86726.1797 - accuracy: 6.3387e-06 - val_loss: 15985011926.5568 - val_mse: 15985012736.0000 - val_mae: 86489.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "157760/157760 [==============================] - 4s 22us/step - loss: 16266369368.7951 - mse: 16266362880.0000 - mae: 86716.7500 - accuracy: 0.0000e+00 - val_loss: 15983393080.9819 - val_mse: 15983392768.0000 - val_mae: 86479.8359 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "157760/157760 [==============================] - 4s 23us/step - loss: 16264745768.9249 - mse: 16264733696.0000 - mae: 86707.5000 - accuracy: 0.0000e+00 - val_loss: 15981774017.7346 - val_mse: 15981772800.0000 - val_mae: 86470.4766 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "157760/157760 [==============================] - 4s 27us/step - loss: 16263127275.0020 - mse: 16263139328.0000 - mae: 86697.9531 - accuracy: 0.0000e+00 - val_loss: 15980162066.7711 - val_mse: 15980160000.0000 - val_mae: 86461.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "157760/157760 [==============================] - 4s 26us/step - loss: 16261504835.8783 - mse: 16261510144.0000 - mae: 86688.7891 - accuracy: 0.0000e+00 - val_loss: 15978540524.7745 - val_mse: 15978524672.0000 - val_mae: 86451.7812 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "157760/157760 [==============================] - 4s 25us/step - loss: 16259879167.8702 - mse: 16259873792.0000 - mae: 86679.3828 - accuracy: 0.0000e+00 - val_loss: 15976920230.7073 - val_mse: 15976916992.0000 - val_mae: 86442.4453 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "157760/157760 [==============================] - 4s 27us/step - loss: 16258255729.9473 - mse: 16258256896.0000 - mae: 86670.1406 - accuracy: 0.0000e+00 - val_loss: 15975301232.8345 - val_mse: 15975301120.0000 - val_mae: 86433.1328 - val_accuracy: 2.5354e-05\n",
      "Epoch 10/10\n",
      "157760/157760 [==============================] - 4s 25us/step - loss: 16256634049.3955 - mse: 16256659456.0000 - mae: 86660.7344 - accuracy: 6.3387e-06 - val_loss: 15973686436.3447 - val_mse: 15973687296.0000 - val_mae: 86423.7891 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "results=model.fit(X_train,y_train,epochs=10,batch_size=50,validation_split=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use mix max scalar? not Standard??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tens)",
   "language": "python",
   "name": "tens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

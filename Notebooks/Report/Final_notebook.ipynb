{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Notebook-Comprehensive Notebook detailing the process to the final model and project overview.\n",
    "\n",
    "# Overview of Project\n",
    " This project aims to utilize Illinois 2018 American Community Survey data to create an imcome predicitor to aid Illinois and governmental programs with their allocation of the programs. In particular programs such as SNAP and unemployment. This will allow for a faster application process due to better accuracy. This is very crucial in especially when looking at unemployment. This has been one of the most vital neccesities of this COVID-19 age due to the massive amount of layoff/furloughs done by organizations. In creating a better system to access these individuals and their income we can better deploy these services to the citizens that need them. More information on this topic can be found [here]\n",
    " \n",
    "# Data acquisition \n",
    " Prior to running any of the Jupyter Notbooks or data in this download the neccesary files and create the environments found within them.\n",
    "\n",
    "Download [Andaconda](https://docs.anaconda.com/anaconda/install/) to be able to install the environment and use your preference of commandline options or Editor to view the data.\n",
    "Also go to this [Census Link](https://www2.census.gov/programs-surveys/acs/data/pums/2018/5-Year/) and down load the csv_hil.zip to acquires the data used in this project.\n",
    "\n",
    "### From the list options below choose the environments within this neccesary envrionment for your operating system.\n",
    "\n",
    "[`Capstone.yml`]\n",
    "\n",
    "To utilize Geopandas:\n",
    "\n",
    "[`geopandas.yml`]\n",
    "\n",
    "All files are located in the main directory and src folder.\n",
    "Run these two lines of code after the download to apply the kernals to your IDE.\n",
    "\n",
    "`python -m ipykernel install --user --name tens --display-name \"Python 3 (tens)\"` \n",
    "\n",
    "`python -m ipykernel install --user --name Capstone --display-name \"Python 3 (Capstone)\"`  \n",
    "\n",
    " \n",
    "# Goals:\n",
    "This project aims to:\n",
    "- Build a modle that predicts an individuals income based on multiple parameters such as property value, proterty taxes and number of people in a household."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.js_functions import training_data\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from src.js_functions import  process_data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../../Data/csv_hil/psam_h17.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The orginal dataframe will now processed via the process data function. For more about the cleaning and processing of the data [check out this notbook](../Explortatory/Data_cleaning_processing.ipynb) as well as [this py file](../../src/js_functions.py).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test=process_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that the data is proccessed and loaded let run our initial model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is our baseline model.\n",
    "lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3847594087743529"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores= cross_val_score(lr,X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38422207389115826"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basline model has a R-squared score of .38 so not to bad as basline model. Let's see if we can increase this value through a different algorithm. Overall, This initial model is telling that 38% of the variance seen in the target columns is due to the current features we are using.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets run our Random forest regressor seeing as this was the best model from the model iteration process. For a more detail dive into this open [KNN notebook](../Explortatory/KNN_regressor.ipynb), [Neural Networks](../Explortatory/Neural_networks.ipynb), [Random Forest Regressor notebook](../Explortatory/Random_forest_regressor.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr=RandomForestRegressor(max_depth=10, min_samples_split= 4, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=10, min_samples_split=4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4707455075369493"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores= cross_val_score(rfr,X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4071296998755914"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets see how our final model preforms on the test data set for a final evaluation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41705033057573215"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1= cross_val_score(rfr,X_test,y_test,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4074608004753443"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **The model performs well on the test data where the level of vairance association is not to far off from the training data. With some more iteration we may be able to increase this value and create are more accurate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat=rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual=86708.29873633395, Predictied=86634.44640730703\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual=%s, Predictied=%s\" % (y_test.values.mean(),y_hat.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From this we can see that our actual value  and predicted value average do not differ to much which makes sense due to the model trying to acomodate all the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual=35000.0, Predictied=64088.77956877114\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual=%s, Predictied=%s\" % (y_test.values[0],y_hat[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However, when we look at the individual values and their predicted income counterparts there is a large discrepancy in some case such as the first value of the test data being 35,000 and the predcited value being 64,000. This is something I expected due to combining all of the counties in one dataframe. This is due to the cost of living and overall socio-economic advantages or disadvantages of a county based on it geographical location**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End analysis conlusion:\n",
    "- The final model predicts about 40% of the vairiance seen within the data. \n",
    "- When looking at this from a quantitative standpoint there is about ~70 dollar average differece in the actual and predicted values with this model. However, when you look at individual values there is about a 29,000 dollar differnce in those values.\n",
    "\n",
    "### Next steps:\n",
    "- I would like to continue to Iterate on the current model and reduce the amount of vairance seen between the actual and predicted values.\n",
    "- I would also like to subset the counties and see how that would affect the predicted values due to haveing more geographically related data.\n",
    "- Moreover, I would like to do some more feature enginerring to possiblty increase the R-Squared value.\n",
    "- Lastly, I would like to find more recent census data to have a better estimate to the current day household income."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Capstone)",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
